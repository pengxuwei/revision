\relax 
\citation{torralba2003contextual,torralba2004contextual}
\citation{wang2001simplicity,chang2003cbsa,vailaya1999content}
\citation{siagian2005gist,manduchi2005obstacle}
\citation{quelhas2005modeling,galleguillos2008object}
\citation{li2014object}
\citation{kwitt2012scene}
\citation{fei2005bayesian,bosch2006scene,bosch2008scene,rasiwasia2012holistic}
\citation{van2010visual}
\citation{hofmann1999probabilistic}
\citation{blei2003latent}
\citation{van2010visual}
\citation{fei2005bayesian,bosch2006scene,bosch2008scene}
\citation{blei2003latent}
\citation{blei2006correlated,blei2007correction}
\citation{aitchison1986statistical}
\citation{bosch2006scene,bosch2008scene}
\citation{quelhas2007thousand}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\newlabel{Sec:Introduction}{{I}{1}}
\citation{zhou2014learning}
\citation{krizhevsky2012imagenet}
\citation{deng2009imagenet}
\citation{donahue2013decaf}
\citation{joachims1998text}
\citation{csurka2004visual}
\citation{li2010object,li2014object}
\citation{xiao2014sun}
\citation{zhou2014learning}
\citation{jaakkola1999exploiting}
\citation{aitchison1986statistical}
\citation{perronnin2007fisher}
\citation{jegou2010aggregating}
\citation{holub2005combining}
\citation{kobayashi2014dirichlet}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{2}}
\newlabel{Sec:RelatedWork}{{II}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Examples of \emph  {village} and \emph  {coast} scene images. In the first row, histograms of visual words are shown; Themes are provided for three images, among which two images of scene \emph  {village} and one image of scene \emph  {coast} present in the second row; Their corresponding theme probability distributions are shown in the fourth row.}}{2}}
\newlabel{Fig:scene}{{1}{2}}
\citation{cinbis2012image,cinbis2015approximate}
\citation{van2008visualizing}
\citation{van2008visualizing}
\citation{cinbis2012image,cinbis2015approximate}
\citation{atchison1980logistic}
\citation{aitchison1986statistical}
\citation{blei2007correction}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Correlated Topic Model learning and Correlated Topic Vector encoding.}}{3}}
\newlabel{Fig:flowchart}{{2}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces The Generating Process of Image $d$.}}{3}}
\newlabel{Table:table_ctm}{{I}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Methodology}{3}}
\newlabel{Sec:Methodology}{{III}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Latent Semantic Representation}{3}}
\citation{oliva2001modeling}
\citation{oliva2001modeling}
\citation{quelhas2007thousand}
\citation{rasiwasia2012holistic}
\citation{zhou2014learning}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Feature visualization using t-sne \cite  {van2008visualizing}. We visualize three types features on the SCENE 8 dataset, bow, latent semantic representations of LDA and CTM. It can observed that latent semantic features derived from LDA are more compact than BoW, while latent semantic features of CTM demonstrate a superior cluster effect for all the scene categories in semantic feature space. (Best viewed in color.)}}{4}}
\newlabel{Fig:feature visualization}{{3}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Performance of CTM based latent semantic representation on the SCENE 8 dataset \cite  {oliva2001modeling}.}}{4}}
\newlabel{Fig:performance of CTM}{{4}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Correlated Topic Vector}{4}}
\citation{jordan1999introduction}
\citation{jordan1999introduction}
\citation{blei2006correlated}
\citation{blei2007correction}
\citation{perronnin2010improving}
\citation{sanchez2013image}
\citation{chen2013scalable}
\citation{mimno2008gibbs}
\citation{chen2013scalable}
\citation{salimans2014markov}
\citation{salimans2014markov}
\newlabel{Equ:Lvb}{{3}{5}}
\newlabel{Equ:u-mu}{{4}{5}}
\newlabel{Equ:u-Sigma}{{5}{5}}
\newlabel{Equ:u-beta}{{6}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Gibbs Sampling Solution}{5}}
\citation{krizhevsky2012imagenet,donahue2013decaf,jia2014caffe}
\citation{donahue2013decaf}
\citation{krizhevsky2012imagenet}
\citation{kwitt2012scene,cinbis2015approximate,gong2014multi}
\citation{deng2009imagenet}
\citation{gong2014multi}
\citation{quattoni2009recognizing}
\citation{perronnin2007fisher,sanchez2013image,chatfield2011devil}
\citation{chang2011libsvm}
\citation{gong2014multi}
\citation{quattoni2009recognizing}
\citation{xiao2010sun,xiao2014sun}
\citation{jia2014caffe}
\citation{deng2009imagenet}
\citation{zhou2014learning}
\citation{dixit2015scene}
\citation{dixit2015scene}
\citation{gong2014multi}
\citation{kwitt2012scene}
\citation{bergamo2014classemes}
\citation{xiao2010sun}
\citation{donahue2013decaf}
\citation{zhou2014learning}
\citation{gong2014multi}
\citation{dixit2015scene}
\citation{zhou2014learning}
\citation{cinbis2015approximate}
\citation{liu2014encoding}
\citation{dixit2015scene}
\citation{dixit2015scene}
\citation{gong2014multi}
\citation{li2014object}
\citation{donahue2013decaf}
\citation{juneja2013blocks}
\citation{doersch2013mid}
\citation{zhou2014learning}
\citation{dixit2015scene}
\citation{dixit2015scene}
\citation{gong2014multi}
\citation{dixit2015scene}
\citation{zhou2014learning}
\citation{gong2014multi}
\citation{dixit2015scene}
\citation{dixit2015scene}
\citation{dixit2015scene}
\citation{gong2014multi}
\citation{dixit2015scene}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-D}}CNN-based Implementation}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Comparison of CNN-BoW and deep-BoW on the MIT Indoor 67 dataset.}}{6}}
\newlabel{Fig:Comparison BoW}{{5}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experiments}{6}}
\newlabel{Sec:Experiments}{{IV}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Setup}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Main Results}{6}}
\citation{chen2013scalable}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Comparison on the SUN 397 Dataset.}}{7}}
\newlabel{Table:result-SUN397}{{II}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Evaluation of Features Extracted at Different Scales}}{7}}
\newlabel{Table:scales}{{III}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Comparison on the MIT Indoor 67 Dataset}}{7}}
\newlabel{Table:result-mitindoor67}{{IV}{7}}
\citation{gong2014multi}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  Recognition results of the \emph  {village} scene. In the first row, they are true positive for the CTV but false negative for the CNN features. In the three rows below them, these three images are from the scene category that they are wrongly recognized as with CNN features respectively.}}{8}}
\newlabel{Fig:village examples of CTV}{{6}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Region examples.}}{8}}
\newlabel{Fig:village patches}{{7}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Recognition results of four scene categories. For each category, we give one image which is the true positive of the CTV-GS but the false negative of CNN feature, and three negative images from a very similar category.}}{8}}
\newlabel{Fig:CTV examples of other categories}{{8}{8}}
\citation{liu2014encoding}
\citation{liu2014encoding}
\citation{cinbis2015approximate}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Topic correlation matrix. The first and second columns are those for 8 topics on the SUN 397 dataset and MIT Indoor 67 dataset, and the last two are for 16 topics on both datasets. Solid circle stands for positive correlation between two topics, while open circle represents negative correlation between two topics. Larger radius, larger positive/negative correlation.}}{9}}
\newlabel{Fig:correlation matrix}{{9}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Evaluation of Parameters}{9}}
\bibstyle{IEEEtran}
\bibdata{IEEEabrv,reference}
\bibcite{torralba2003contextual}{1}
\bibcite{torralba2004contextual}{2}
\bibcite{wang2001simplicity}{3}
\bibcite{chang2003cbsa}{4}
\bibcite{vailaya1999content}{5}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Evaluation of topic numbers on the MIT Indoor 67 dataset.}}{10}}
\newlabel{Fig:Evaluation of topic number}{{10}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{10}}
\newlabel{Sec:Conclusion}{{V}{10}}
\@writefile{toc}{\contentsline {section}{Appendix\nobreakspace  A: Derivation of CTV with Variational Bayesian solution}{10}}
\newlabel{Sec:Appendix A}{{A}{10}}
\newlabel{Equa:appendix}{{10}{10}}
\newlabel{Equa:appendix-mu}{{11}{10}}
\newlabel{Equa:appendix-sigma}{{12}{10}}
\newlabel{Equa:appendix-beta}{{13}{10}}
\@writefile{toc}{\contentsline {section}{References}{10}}
\bibcite{siagian2005gist}{6}
\bibcite{manduchi2005obstacle}{7}
\bibcite{quelhas2005modeling}{8}
\bibcite{galleguillos2008object}{9}
\bibcite{li2014object}{10}
\bibcite{kwitt2012scene}{11}
\bibcite{fei2005bayesian}{12}
\bibcite{bosch2006scene}{13}
\bibcite{bosch2008scene}{14}
\bibcite{rasiwasia2012holistic}{15}
\bibcite{van2010visual}{16}
\bibcite{hofmann1999probabilistic}{17}
\bibcite{blei2003latent}{18}
\bibcite{blei2006correlated}{19}
\bibcite{blei2007correction}{20}
\bibcite{aitchison1986statistical}{21}
\bibcite{quelhas2007thousand}{22}
\bibcite{zhou2014learning}{23}
\bibcite{krizhevsky2012imagenet}{24}
\bibcite{deng2009imagenet}{25}
\bibcite{donahue2013decaf}{26}
\bibcite{joachims1998text}{27}
\bibcite{csurka2004visual}{28}
\bibcite{li2010object}{29}
\bibcite{xiao2014sun}{30}
\bibcite{jaakkola1999exploiting}{31}
\bibcite{perronnin2007fisher}{32}
\bibcite{jegou2010aggregating}{33}
\bibcite{holub2005combining}{34}
\bibcite{kobayashi2014dirichlet}{35}
\bibcite{cinbis2012image}{36}
\bibcite{cinbis2015approximate}{37}
\bibcite{van2008visualizing}{38}
\bibcite{atchison1980logistic}{39}
\bibcite{oliva2001modeling}{40}
\bibcite{jordan1999introduction}{41}
\bibcite{perronnin2010improving}{42}
\bibcite{sanchez2013image}{43}
\bibcite{chen2013scalable}{44}
\bibcite{mimno2008gibbs}{45}
\bibcite{salimans2014markov}{46}
\bibcite{jia2014caffe}{47}
\bibcite{gong2014multi}{48}
\bibcite{quattoni2009recognizing}{49}
\bibcite{chatfield2011devil}{50}
\bibcite{chang2011libsvm}{51}
\bibcite{xiao2010sun}{52}
\bibcite{dixit2015scene}{53}
\bibcite{bergamo2014classemes}{54}
\bibcite{liu2014encoding}{55}
\bibcite{juneja2013blocks}{56}
\bibcite{doersch2013mid}{57}
